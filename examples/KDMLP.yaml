# python run_experiments.py -c KDMLP.yaml -nc "trainer.gpu=1" "model.aug.k=9" "meta.dataset_name='CiteSeer'" "trainer.kd.knowledge_dir='./examples/ckpt/CiteSeer_GCN/'"
# python run_experiments.py -c KDMLP.yaml
# python run_experiments.py -c KDMLP.yaml -nc "meta.dataset_name='CiteSeer'" "trainer.kd.knowledge_dir='./examples/ckpt/CiteSeer_GCN/'"
# python run_experiments.py -c KDMLP.yaml -nc "trainer.gpu=1" "meta.dataset_name='ogbn-arxiv'" "trainer.kd.knowledge_dir='./examples/ckpt/ogbn-arxiv_GCN/'" "model.knn.hop=0"

meta:
  model_name: KDModel
  student_name: MLP
  dataset_name: Cora
  n_runs: 1

dataset:
  num_features: ~
  num_classes: ~

model:
  num_hiddens: 256
  num_layers: 3
  dropout: 0.5
  batch_norm: True
  knn:
    k: 20
    hop: 2
  raw:
    hop: 2
  feat_combine: 'transform' # attn mean transform

trainer:
  lr: 0.001
  weight_decay: 0
  epochs: 800
  verbose: True
  ckpt_dir: ./examples/ckpt/test_KD
  gpu: 0

  kd:
    knowledge_dir: ./examples/ckpt/Cora_GCN/
    method: soft     # none, soft, hidden, logit, feats, ce_link, soft_link, ce_recover
    mask: train_val_unlabeled     # train_val, train_val_test, all, train_val_unlabeled
    alpha: 1
    beta: 1.
    temperature: 20
    neg_k: 20