# python run_experiments.py -c MLP.yaml -nc "trainer.gpu=1" "model.aug.k=0"


meta:
  model_name: MLP
  dataset_name: Cora
  n_runs: 1

dataset:
  num_features: ~
  num_classes: ~

model:
  num_hiddens: 256
  num_layers: 3
  dropout: 0.5
  batch_norm: True
  aug:
    k: 0
    combine: cat # cat

trainer:
  lr: 0.01
  weight_decay: !!float 5e-4
  epochs: 400
  verbose: True
  # ckpt_dir: ./examples/ckpt/test_GAT
  gpu: 1
